{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "# Importing the relevent directories\r\n",
    "\r\n",
    "from splinter import Browser\r\n",
    "from bs4 import BeautifulSoup\r\n",
    "from webdriver_manager.chrome import ChromeDriverManager\r\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Scraping data using Splinter for https://redplanetscience.com/ where we need the Latest news title and paragraph"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Setup splinter\r\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\r\n",
    "browser = Browser('chrome', **executable_path, headless=False)\r\n",
    "\r\n",
    "marslatest = {}\r\n",
    "\r\n",
    "# URL for NASA Mars News\r\n",
    "url = 'https://redplanetscience.com/'\r\n",
    "browser.visit(url)\r\n",
    "     \r\n",
    "# HTML object\r\n",
    "html = browser.html\r\n",
    "\r\n",
    "# Parse HTML with Beautiful Soup\r\n",
    "soup = BeautifulSoup(html, 'html.parser')\r\n",
    "\r\n",
    "# Retrieve all elements that contain book information\r\n",
    "latestnews = soup.find_all('div', class_='list_text')\r\n",
    "\r\n",
    "for news in latestnews:\r\n",
    "    marslatest[\"title\"]     = news.find(class_='content_title').get_text()\r\n",
    "    marslatest[\"paragraph\"] = news.find(class_='article_teaser_body').get_text()\r\n",
    "    print(marslatest)\r\n",
    "    print(\"---------------------------------------------------------------------------------------------------------------------\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "browser.quit()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Scraping image using Splinter from https://spaceimages-mars.com/ for latest featured Mars Image"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "executable_path = {'executable_path': ChromeDriverManager().install()}\r\n",
    "browser = Browser('chrome', **executable_path, headless=False)\r\n",
    "    \r\n",
    "# URL for NASA Mars featured image\r\n",
    "url = 'https://spaceimages-mars.com/'\r\n",
    "browser.visit(url)\r\n",
    "      \r\n",
    "# HTML object\r\n",
    "html = browser.html\r\n",
    "\r\n",
    "# Parse HTML with Beautiful Soup\r\n",
    "soup = BeautifulSoup(html, 'html.parser')\r\n",
    "\r\n",
    "# Retrieve the header image from Space Image website\r\n",
    "marsimage       = soup.find('img', class_='headerimage fade-in') \r\n",
    "   \r\n",
    "image           = marsimage['src']\r\n",
    "\r\n",
    "# Saving the the web link in featured_image)url\r\n",
    "featured_image_url = ('https://spaceimages-mars.com/' + image)\r\n",
    "\r\n",
    "print(featured_image_url)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "browser.quit()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Scraping with Pandas"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "url = 'https://galaxyfacts-mars.com/'\r\n",
    "tables = pd.read_html(url)\r\n",
    "tables"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Transpose the Mars Planet Profile table with appropriate Headers"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "profile_df = tables[1]\r\n",
    "\r\n",
    "transpose_profile_df = profile_df.transpose()\r\n",
    "transpose_profile_df.columns = transpose_profile_df.iloc[0]\r\n",
    "transpose_profile_df = transpose_profile_df[1:]\r\n",
    "transpose_profile_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Converting the Mars Planet Profile Pandas Dataframe to HTML table"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "html_profile_table = transpose_profile_df.to_html()\r\n",
    "html_profile_table"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Transpose the Mars - Earth Comparision table with appropriate Headers"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "comparision_df = tables[0]\r\n",
    "transpose_comp_df = comparision_df.transpose()\r\n",
    "transpose_comp_df.columns = transpose_comp_df.iloc[0]\r\n",
    "transpose_comp_df = transpose_comp_df[1:]\r\n",
    "transpose_comp_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Converting the Mars - Earth Comparision Pandas Dataframe to HTML table"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "html_comp_table = transpose_comp_df.to_html()\r\n",
    "html_comp_table"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Scraping the Titles and image url from Mars Hemisphere website"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    " # Setup splinter\r\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\r\n",
    "browser = Browser('chrome', **executable_path, headless=False)\r\n",
    "\r\n",
    "# URL for NASA Mars News\r\n",
    "url = 'https://marshemispheres.com/'\r\n",
    "browser.visit(url)\r\n",
    "\r\n",
    "hemisphere_images_urls = {}\r\n",
    "\r\n",
    "# HTML object\r\n",
    "html = browser.html\r\n",
    "\r\n",
    "# Parse HTML with Beautiful Soup\r\n",
    "soup = BeautifulSoup(html, 'html.parser')\r\n",
    "\r\n",
    "# Retrieve all elements that contain book information\r\n",
    "images = soup.find_all('div', class_='description')\r\n",
    "\r\n",
    "for image in images:\r\n",
    "    hemisphere_images_urls[\"title\"] = image.find('h3').get_text()\r\n",
    "    a = image.find('a')\r\n",
    "    href = a['href']\r\n",
    "\r\n",
    "    url2 = \"https://marshemispheres.com/\" + href\r\n",
    "    browser.visit(url2)\r\n",
    "\r\n",
    "    html = browser.html\r\n",
    "\r\n",
    "    soup = BeautifulSoup(html, 'html.parser')\r\n",
    "\r\n",
    "    wideimage = soup.find(class_='wide-image')\r\n",
    "    #image2    = wideimage.find(class_='wide-image')\r\n",
    "    imageurl = wideimage['src']\r\n",
    "\r\n",
    "    hemisphere_images_urls[\"img_url\"] = \"https://marshemispheres.com/\" + imageurl\r\n",
    "\r\n",
    "    print(hemisphere_images_urls)\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "browser.quit()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.10 64-bit ('PythonData2': conda)"
  },
  "interpreter": {
   "hash": "e0b418b09ac47957412e0b1b3ad755156e145bf5e9f3a21911cb1dcef404ebf8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}